{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from functions import winsor, sPCAest\n",
    "from scipy.ndimage import shift\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250,)\n",
      "(250,)\n",
      "(250, 500)\n",
      "y_t:  [-1.51274368 -1.01074068  1.37232345  1.07421144  2.01828909  0.30852996\n",
      "  0.46436283 -0.64358596 -1.69906167  1.74191539]\n",
      "y_h:  [-1.01074068  1.37232345  1.07421144  2.01828909  0.30852996  0.46436283\n",
      " -0.64358596 -1.69906167  1.74191539 -2.00727577]\n",
      "\n",
      "e:  [-1.43182647  0.7079561   0.42051982  1.15020388  0.15191228 -1.52350218\n",
      " -0.78313068 -2.3888026  -0.85077465 -1.75814383]\n",
      "g:  [ 0.4210858   0.66436734  0.65369162  0.86808521  0.15661768  1.98786502\n",
      "  0.13954472  0.68974093  2.59269005 -0.24913194]\n"
     ]
    }
   ],
   "source": [
    "def generate_data(n, T, N, h_steps=1):\n",
    "    # Generate y_{t + h} = g_t + e_{t + h}\n",
    "    # e_{t + h} ~ N(0, 1)\n",
    "    # g_t ~ N(0, 1)\n",
    "    # X_t,i = g_t*phi_i + h_t*psi_i + u_t,i\n",
    "\n",
    "    # Set T to T + h to account for lag\n",
    "    T_plus_h = T + h_steps\n",
    "\n",
    "    # Generate g_t\n",
    "    g = np.random.normal(0, 1, T_plus_h)\n",
    "\n",
    "    # Generate h_t\n",
    "    h = np.random.normal(0, 1, T_plus_h)\n",
    "\n",
    "    # Generate e_t+h\n",
    "    e = np.random.normal(0, 1, T_plus_h)\n",
    "\n",
    "    # Generate y_{t+h}\n",
    "    y_h = g + e\n",
    "\n",
    "    # Generate y_t\n",
    "    y_t = np.zeros(T_plus_h)\n",
    "    for i in range(h_steps, T_plus_h):\n",
    "        y_t[i] = y_h[i - h_steps]\n",
    "\n",
    "    # Generate phi_i (Nx1) with n < N nonzero elements\n",
    "    phi = np.zeros(N)\n",
    "    phi[:n] = np.random.uniform(0, 1, n)\n",
    "\n",
    "    # Generate psi_i (Nx1) with n < N nonzero elements\n",
    "    psi = np.zeros(N)\n",
    "    psi[:n] = np.random.uniform(0, 1, n)\n",
    "\n",
    "    # Generate idiosyncratic error's variances\n",
    "    variance_u = np.random.uniform(0, 1, N)\n",
    "\n",
    "    # Generate covariance matrix for u_t\n",
    "    sigma_u = np.diag(variance_u)\n",
    "\n",
    "    # Generate u\n",
    "    u = np.random.multivariate_normal(np.zeros(N), sigma_u, T)\n",
    "\n",
    "    # Drop first h rows\n",
    "    y_h = y_h[h_steps:]\n",
    "    y_t = y_t[h_steps:]\n",
    "    e = e[h_steps:]\n",
    "    g = g[h_steps:]\n",
    "    h = h[h_steps:]\n",
    "\n",
    "    \n",
    "\n",
    "    # Generate X_t\n",
    "    X = np.zeros((T, N))\n",
    "    for i in range(N):\n",
    "        X[:, i] = g*phi[i] + h*psi[i] + u[:, i]\n",
    "\n",
    "    results = {'y_t':y_t,\n",
    "               'y_h':y_h,\n",
    "                'X':X,\n",
    "                'g':g,\n",
    "                'e':e,\n",
    "                }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Testing\n",
    "results = generate_data(10, T=250, N=500, h_steps=1)\n",
    "y_t = results['y_t']\n",
    "y_h = results['y_h']\n",
    "X = results['X']\n",
    "e = results['e']\n",
    "g = results['g']\n",
    "\n",
    "print(y_t.shape)\n",
    "print(y_h.shape)\n",
    "print(X.shape)\n",
    "\n",
    "print('y_t: ', y_t[:10])\n",
    "print('y_h: ', y_h[:10])\n",
    "print()\n",
    "print('e: ', e[:10])\n",
    "print('g: ', g[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_PCA(n=10, T=250, N=500, h_steps=1, R=10, nfac=2):\n",
    "    # Initialize the MSE vector\n",
    "    error_mat = np.zeros((R, 50 - h_steps - 1))\n",
    "\n",
    "    for r in range(R):\n",
    "        print(\"Run {}\".format(r))\n",
    "        variables = generate_data(n=n, T=T, h_steps=h_steps, N=N)\n",
    "\n",
    "        # y_t contains the values of y at time t, and y_h contains the values of y at time t+h\n",
    "        # X contains the values of X at time t\n",
    "        y_h = variables['y_h']\n",
    "        y_t = variables['y_t']\n",
    "        X = variables['X']\n",
    "\n",
    "        g = variables['g']\n",
    "\n",
    "        # Loop for expanding window estimation\n",
    "        # The initial window size is 200 observations\n",
    "        # The window size is increased by 1 observation at each iteration\n",
    "        # The window size is increased until it reaches 250 observations\n",
    "\n",
    "        # Initialize the error vector\n",
    "        error = np.zeros((50 - h_steps - 1, 1))\n",
    "\n",
    "        for t in range(50 - h_steps - 1):\n",
    "            # Split data into training and testing sets\n",
    "            # Training set is the first 200 + t observations\n",
    "            # Testing set is the last 50 - t observations\n",
    "            idx_split = 200 + t\n",
    "\n",
    "            y_train = y_t[:idx_split]\n",
    "            y_test = y_t[idx_split]\n",
    "\n",
    "            X_train = X[:idx_split]\n",
    "\n",
    "            y_train_h = y_h[:idx_split]\n",
    "            # Estimate the parameters of the model using sPCAest\n",
    "            # The function sPCAest is defined in functions.py\n",
    "            #factors, _ = sPCAest(target=y_train_h, X=X_train_h, nfac=nfac)\n",
    "            pca = PCA(n_components=nfac)\n",
    "            X_normalized = StandardScaler(with_mean=True, with_std=True).fit_transform(X_train)\n",
    "            pca.fit(X_normalized)\n",
    "            factors = pca.transform(X_normalized)\n",
    "                \n",
    "            reg = LinearRegression().fit(factors, y_train_h)\n",
    "\n",
    "            # Predict y_{t+h} using the estimated parameters\n",
    "            y_pred = reg.predict(factors[-1].reshape(1, -1))\n",
    "\n",
    "            # Compute the error\n",
    "            error[t] = y_pred - y_test\n",
    "            \n",
    "        print(\"MSE of run {} is {}\".format(r, np.mean(error**2)))\n",
    "        error_mat[r,:] = error.flatten()\n",
    "\n",
    "    return error_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "MSE of run 0 is 1.0769235762828442\n",
      "Run 1\n",
      "MSE of run 1 is 0.9949275978377182\n",
      "Run 2\n",
      "MSE of run 2 is 1.0507670075972764\n",
      "Run 3\n",
      "MSE of run 3 is 1.2235095263527922\n",
      "Run 4\n",
      "MSE of run 4 is 1.1199560712221495\n",
      "Run 5\n",
      "MSE of run 5 is 1.9306840972537669\n",
      "Run 6\n",
      "MSE of run 6 is 1.8204256328951633\n",
      "Run 7\n",
      "MSE of run 7 is 1.5634360837626557\n",
      "Run 8\n",
      "MSE of run 8 is 1.0656478588151697\n",
      "Run 9\n",
      "MSE of run 9 is 1.1336294218555947\n"
     ]
    }
   ],
   "source": [
    "# Run the simulation\n",
    "errors = simulate_PCA(n=50, T=250, N=500, h_steps=1, R=10, nfac=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median MSE is 1.126792746538872\n",
      "MSE is [1.07692358 0.9949276  1.05076701 1.22350953 1.11995607 1.9306841\n",
      " 1.82042563 1.56343608 1.06564786 1.13362942]\n"
     ]
    }
   ],
   "source": [
    "mse_vec = (errors**2).mean(axis=1)\n",
    "median_mse = np.median(mse_vec)\n",
    "print(\"Median MSE is {}\".format(median_mse))\n",
    "print(\"MSE is {}\".format(mse_vec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
