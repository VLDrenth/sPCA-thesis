{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from functions import winsor, corr_uniform, sPCAest\n",
    "from scipy.ndimage import shift\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA, KernelPCA, SparsePCA, FastICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak factor case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250,)\n",
      "(250,)\n",
      "(250, 500)\n",
      "y_t:  [ 0.05987219  0.94242811 -1.90025016 -1.00953636 -1.81306809 -0.35928276\n",
      "  0.53298677 -1.08345965  1.29815511  2.40004253]\n",
      "y_h:  [ 0.94242811 -1.90025016 -1.00953636 -1.81306809 -0.35928276  0.53298677\n",
      " -1.08345965  1.29815511  2.40004253  0.43963098]\n",
      "\n",
      "e:  [ 0.28987748 -1.45974756 -0.44667645 -1.82236392 -0.27448564 -0.18658702\n",
      " -0.06461369  1.68464557  0.33557557  1.00175189]\n",
      "g:  [ 0.65255063 -0.4405026  -0.56285991  0.00929583 -0.08479713  0.71957379\n",
      " -1.01884596 -0.38649046  2.06446697 -0.56212091]\n"
     ]
    }
   ],
   "source": [
    "def generate_data(n, T, N, h_steps=1, heteroskedastic=False, psi_max=None, rho=None):\n",
    "    # Check if weak or strong factor model\n",
    "    if n == N:\n",
    "        # Strong factor model, require psi_max and rho\n",
    "        assert psi_max is not None\n",
    "        assert rho is not None\n",
    "\n",
    "    # Generate y_{t + h} = g_t + e_{t + h}\n",
    "    # e_{t + h} ~ N(0, 1)\n",
    "    # g_t ~ N(0, 1)\n",
    "    # X_t,i = g_t*phi_i + h_t*psi_i + u_t,i\n",
    "\n",
    "    # Set T to T + h to account for lag\n",
    "    T_plus_h = T + h_steps\n",
    "\n",
    "    # Generate g_t\n",
    "    g = np.zeros(T_plus_h)\n",
    "    g = np.random.normal(0, 1, T_plus_h)\n",
    "\n",
    "    # Generate h_t\n",
    "    h = np.zeros(T_plus_h)\n",
    "    h = np.random.normal(0, 1, T_plus_h)\n",
    "    \n",
    "    # Generate e_t+h\n",
    "    e = np.zeros(T_plus_h)\n",
    "    e = np.random.normal(0, 1, T_plus_h)\n",
    "\n",
    "    # Generate y_{t+h}\n",
    "    y_h = np.zeros(T_plus_h)\n",
    "    y_h = g + e\n",
    "\n",
    "    # Generate y_t\n",
    "    y_t = np.zeros(T_plus_h)\n",
    "    y_t[h_steps:T_plus_h] = y_h[:T]\n",
    "\n",
    "    phi = np.zeros(N)\n",
    "    psi = np.zeros(N)\n",
    "\n",
    "    if n < N:\n",
    "        # Generate phi_i (Nx1) with n < N nonzero elements\n",
    "        phi[:n] = np.random.uniform(0, 1, n)\n",
    "\n",
    "        # Generate psi_i (Nx1) with n < N nonzero elements\n",
    "        psi[:n] = np.random.uniform(0, 1, n)\n",
    "\n",
    "        # Generate idiosyncratic error's variances\n",
    "        variance_u = np.random.uniform(0, 1, N)        \n",
    "    elif n == N:\n",
    "        # Phi is U(0, phi_max)\n",
    "        psi = np.random.uniform(0, psi_max, N)\n",
    "\n",
    "        # Draw correlated phi and sigma_u\n",
    "        # Generate correlation matrix for phi and sigma_u\n",
    "        phi, variance_u = corr_uniform(rho=rho*1.1, size=N)\n",
    "\n",
    "    u = np.zeros((T, N))\n",
    "    # Generate u_t,i depending on whether the model is heteroskedastic or not\n",
    "    if heteroskedastic:\n",
    "        for t in range(T):\n",
    "            scale = np.random.uniform(0.5, 1.5)\n",
    "            u[t, :] = np.random.normal(0, variance_u * scale, N)\n",
    "    else:\n",
    "        # Generate u\n",
    "        u = np.random.multivariate_normal(mean=np.zeros(N), cov=np.diag(variance_u), size=T)\n",
    "\n",
    "    # Drop first h rows\n",
    "    y_h = y_h[h_steps:]\n",
    "    y_t = y_t[h_steps:]\n",
    "    e = e[h_steps:]\n",
    "    g = g[h_steps:]\n",
    "    h = h[h_steps:]\n",
    "\n",
    "    X = g[:, np.newaxis]*phi[np.newaxis, :] + h[:, np.newaxis]*psi[np.newaxis, :] + u\n",
    "\n",
    "    results = {'y_t':y_t,\n",
    "               'y_h':y_h,\n",
    "                'X':X,\n",
    "                'g':g,\n",
    "                'e':e,\n",
    "                }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Testing\n",
    "results = generate_data(10, T=250, N=500, h_steps=1)\n",
    "y_t = results['y_t']\n",
    "y_h = results['y_h']\n",
    "X = results['X']\n",
    "e = results['e']\n",
    "g = results['g']\n",
    "\n",
    "print(y_t.shape)\n",
    "print(y_h.shape)\n",
    "print(X.shape)\n",
    "\n",
    "print('y_t: ', y_t[:10])\n",
    "print('y_h: ', y_h[:10])\n",
    "print()\n",
    "print('e: ', e[:10])\n",
    "print('g: ', g[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pca(X, y_h, y_t, h_steps=1, nfac=2, method=\"sPCA\", start_test=200):\n",
    "    pca = PCA(n_components=nfac)\n",
    "    reg = LinearRegression()\n",
    "\n",
    "    predicted = np.zeros((1, 50 - h_steps - 1))\n",
    "    error_mat = np.zeros((1, 50 - h_steps - 1))\n",
    "    normalize = StandardScaler(with_mean=True, with_std=True)\n",
    "\n",
    "    for t in range(50 - h_steps - 1):\n",
    "        if t % 10 == 0:\n",
    "            print(\"Period {}\".format(t))\n",
    "\n",
    "        # Split data into training and testing sets\n",
    "        # Training set is the first 200 + t observations\n",
    "        # Testing set is the last 50 - t observations\n",
    "        idx_split = start_test + t\n",
    "        \n",
    "        X_train = X[:idx_split]\n",
    "        y_train = y_h[:idx_split]\n",
    "        y_test = y_t[idx_split]\n",
    "\n",
    "        if method == \"sPCA\":\n",
    "            # Estimate the parameters of the model using sPCAest\n",
    "            # The function sPCAest is defined in functions.py\n",
    "            factors, _ = sPCAest(y_train, X_train, nfac,[0, 100], h_steps)\n",
    "        elif method == \"PCA\":\n",
    "            X_normalized = normalize.fit_transform(X_train)\n",
    "            factors = pca.fit_transform(X_normalized)\n",
    "\n",
    "        reg.fit(factors[:-h_steps,:], y_train[:-h_steps])\n",
    "        \n",
    "        # Predict y_{t+h} using the estimated parameters\n",
    "        y_pred = reg.predict(factors[-1].reshape(1, -1))\n",
    "\n",
    "        # Add predicted value to the predicted vector\n",
    "        predicted[0, t] = y_pred\n",
    "        \n",
    "        # Compute the error\n",
    "        error_mat[0, t] = y_pred - y_test\n",
    "\n",
    "    return error_mat, predicted\n",
    "\n",
    "\n",
    "def simulate_PCA(n=10, T=250, N=500, h_steps=1, R=10, nfac=2, method=\"sPCA\", heteroskedastic=False, psi_max=None, rho=None):\n",
    "    # Initialize the MSE vector\n",
    "    predicted = np.zeros((R, 50 - h_steps - 1))\n",
    "    error_mat = np.zeros((R, 50 - h_steps - 1))\n",
    "\n",
    "    start_test = 200\n",
    "\n",
    "    for r in range(R):\n",
    "        print('r: ', r)\n",
    "        variables = generate_data(n=n, T=T, h_steps=h_steps, N=N, heteroskedastic=heteroskedastic, psi_max=psi_max, rho=rho)\n",
    "\n",
    "        # y_t contains the values of y at time t, and y_h contains the values of y at time t+h\n",
    "        # X contains the values of X at time t\n",
    "        y_h = variables['y_h']\n",
    "        y_t = variables['y_t']\n",
    "        X = variables['X']\n",
    "        \n",
    "        # Loop for expanding window estimation\n",
    "        # The initial window size is 200 observations\n",
    "        # The window size is increased by 1 observation at each iteration\n",
    "        # The window size is increased until it reaches 250 observations\n",
    "        errors, predictions = predict_pca(X, y_h, y_t, h_steps, nfac, method, start_test)\n",
    "            \n",
    "    return error_mat, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r:  0\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  1\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  2\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  3\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  4\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  5\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  6\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  7\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  8\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  9\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  10\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  11\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  12\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  13\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  14\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  15\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  16\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  17\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  18\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n",
      "r:  19\n",
      "Period 0\n",
      "Period 10\n",
      "Period 20\n",
      "Period 30\n",
      "Period 40\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Run the simulationc:\\Users\\Vincent\\Anaconda3New\\envs\\thesis\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:729\n",
    "errors, predictions = simulate_PCA(n=50, T=250, N=500, h_steps=1, R=20, nfac=2, method=\"sPCA\", heteroskedastic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_vec = (errors**2).mean(axis=1)\n",
    "median_mse = np.median(mse_vec)\n",
    "mean_mse = mse_vec.mean()\n",
    "print(\"Median MSE is {}\".format(median_mse))\n",
    "print(\"Mean MSE is {}\".format(mean_mse))\n",
    "print(\"MSE is {}\".format(mse_vec))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot erros of the first run of the simulation\n",
    "plt.plot((predictions[0,:]))\n",
    "plt.title(\"Predicted values of the first run of the simulation\")\n",
    "# Include tick at every other integer\n",
    "plt.xticks(np.arange(0, 50, 2))\n",
    "plt.show()\n",
    "\n",
    "# Plot the histogram of  mean squared error over the different runs\n",
    "plt.hist(mse_vec, bins=40)\n",
    "plt.title(\"Histogram of mean squared error over the different runs\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
