{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (720, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RPI</th>\n",
       "      <th>W875RX1</th>\n",
       "      <th>DPCERA3M086SBEA</th>\n",
       "      <th>CMRMTSPLx</th>\n",
       "      <th>RETAILx</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>IPFPNSS</th>\n",
       "      <th>IPFINAL</th>\n",
       "      <th>IPCONGD</th>\n",
       "      <th>IPDCONGD</th>\n",
       "      <th>...</th>\n",
       "      <th>DSERRG3M086SBEA</th>\n",
       "      <th>CES0600000008</th>\n",
       "      <th>CES2000000008</th>\n",
       "      <th>CES3000000008</th>\n",
       "      <th>UMCSENTx</th>\n",
       "      <th>MZMSL</th>\n",
       "      <th>DTCOLNVHFNM</th>\n",
       "      <th>DTCTHFNM</th>\n",
       "      <th>INVEST</th>\n",
       "      <th>VXOCLSx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sasdate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960-01-01</th>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.016960</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.025916</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.029022</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.103832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001285</td>\n",
       "      <td>-0.004680</td>\n",
       "      <td>0.007797</td>\n",
       "      <td>-0.009705</td>\n",
       "      <td>-2.347448</td>\n",
       "      <td>-0.002451</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.013330</td>\n",
       "      <td>20.704305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-02-01</th>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.014412</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>-0.008937</td>\n",
       "      <td>-0.005684</td>\n",
       "      <td>-0.003439</td>\n",
       "      <td>-0.011455</td>\n",
       "      <td>-0.013858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.004555</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>-0.004750</td>\n",
       "      <td>-1.471062</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>-0.018942</td>\n",
       "      <td>16.198056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-03-01</th>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.014072</td>\n",
       "      <td>-0.028021</td>\n",
       "      <td>-0.001102</td>\n",
       "      <td>-0.009017</td>\n",
       "      <td>-0.003429</td>\n",
       "      <td>-0.001146</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>-0.019963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001025</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.030131</td>\n",
       "      <td>-0.004684</td>\n",
       "      <td>-3.569769</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>31.832723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-04-01</th>\n",
       "      <td>0.003426</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>0.015382</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>0.025903</td>\n",
       "      <td>-0.007961</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>-0.001189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>-0.008949</td>\n",
       "      <td>-0.068074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.501161</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.024136</td>\n",
       "      <td>8.951634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-05-01</th>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>-0.020417</td>\n",
       "      <td>-0.031588</td>\n",
       "      <td>-0.015047</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.009454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.008949</td>\n",
       "      <td>0.041620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.552750</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>-0.004827</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>28.284980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RPI   W875RX1  DPCERA3M086SBEA  CMRMTSPLx   RETAILx  \\\n",
       "sasdate                                                                \n",
       "1960-01-01  0.003193  0.004647         0.002784   0.016960  0.026606   \n",
       "1960-02-01  0.001145  0.000919         0.004327   0.014412  0.003696   \n",
       "1960-03-01  0.001910  0.000918         0.014072  -0.028021 -0.001102   \n",
       "1960-04-01  0.003426  0.003621         0.015382   0.009836  0.025903   \n",
       "1960-05-01  0.002403  0.002448        -0.020417  -0.031588 -0.015047   \n",
       "\n",
       "              INDPRO   IPFPNSS   IPFINAL   IPCONGD  IPDCONGD  ...  \\\n",
       "sasdate                                                       ...   \n",
       "1960-01-01  0.025916  0.024100  0.029022  0.031235  0.103832  ...   \n",
       "1960-02-01 -0.008937 -0.005684 -0.003439 -0.011455 -0.013858  ...   \n",
       "1960-03-01 -0.009017 -0.003429 -0.001146  0.001154 -0.019963  ...   \n",
       "1960-04-01 -0.007961  0.002287  0.001146  0.006880 -0.001189  ...   \n",
       "1960-05-01 -0.001143  0.005691  0.006866  0.005698  0.009454  ...   \n",
       "\n",
       "            DSERRG3M086SBEA  CES0600000008  CES2000000008  CES3000000008  \\\n",
       "sasdate                                                                    \n",
       "1960-01-01        -0.001285      -0.004680       0.007797      -0.009705   \n",
       "1960-02-01         0.000767      -0.004555       0.003853      -0.004750   \n",
       "1960-03-01        -0.001025      -0.000020       0.030131      -0.004684   \n",
       "1960-04-01         0.001531      -0.008949      -0.068074       0.000000   \n",
       "1960-05-01         0.000504       0.008949       0.041620       0.000000   \n",
       "\n",
       "            UMCSENTx     MZMSL  DTCOLNVHFNM  DTCTHFNM    INVEST    VXOCLSx  \n",
       "sasdate                                                                     \n",
       "1960-01-01 -2.347448 -0.002451     0.004292 -0.011739 -0.013330  20.704305  \n",
       "1960-02-01 -1.471062 -0.000001     0.008268  0.005388 -0.018942  16.198056  \n",
       "1960-03-01 -3.569769  0.001738     0.003472  0.000951  0.003490  31.832723  \n",
       "1960-04-01  1.501161 -0.001048     0.008678  0.005452  0.024136   8.951634  \n",
       "1960-05-01 -1.552750  0.001035    -0.004827 -0.002067  0.003798  28.284980  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data\n",
    "data = pd.read_csv('../resources/data/data_fred_matlab.csv')\n",
    "\n",
    "# Set date as index of df\n",
    "data['sasdate'] = pd.to_datetime(data['sasdate'])\n",
    "data.set_index('sasdate', inplace=True)\n",
    "\n",
    "# Select only data from 1960-01-01 untill 2019-12-01\n",
    "data = data.loc[(data.index >= '1960-01-01') & (data.index <= '2019-12-01')]\n",
    "\n",
    "# Drop last column (unnamed)\n",
    "data.drop(data.columns[-1], axis=1, inplace=True)\n",
    "\n",
    "print(\"Data shape: \", data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    720.000000\n",
       "mean       0.002095\n",
       "std        0.007478\n",
       "min       -0.044337\n",
       "25%       -0.001667\n",
       "50%        0.002385\n",
       "75%        0.006443\n",
       "max        0.030432\n",
       "Name: INDPRO, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting data properties\n",
    "data['INDPRO'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sample PCA to compare to the original paper. Paper uses Jan 1960 to Dec 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14507952 0.07236077 0.06826797 0.05524381 0.04247924 0.03487933\n",
      " 0.03200963 0.02380381 0.02211282 0.02137014 0.0198711  0.0168038\n",
      " 0.01662294 0.01583996 0.01555252]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA instance: pca\n",
    "pca = PCA(n_components=15)\n",
    "\n",
    "# Normalizer\n",
    "normalizer = StandardScaler(with_mean=True, with_std=True)\n",
    "\n",
    "data_pca = normalizer.fit_transform(data)\n",
    "\n",
    "# Fit the PCA instance to the scaled samples\n",
    "pca.fit(data_pca)\n",
    "\n",
    "# Get the explained variances from pca\n",
    "eigen_values = pca.explained_variance_ratio_\n",
    "\n",
    "# Eigenvectors are the components\n",
    "eigen_vectors = pca.components_\n",
    "\n",
    "print(eigen_values)\n",
    "# Transform the scaled samples: pca_features\n",
    "pca_features = pca.transform(data_pca)\n",
    "\n",
    "plots = 2\n",
    "fig, ax = plt.subplots(plots, 1, figsize=(7, 5))\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "for i in range(plots):\n",
    "    sns.barplot(x = data.index, y=pca_features[:,i], ax=ax[i])\n",
    "    ax[i].set_xlabel('Category')\n",
    "    ax[i].set_ylabel('PCA {}'.format(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 5) fhat shape\n",
      "(720, 5) lambda shape\n",
      "(128, 720) f_dot_lambda shape\n",
      "[8.74696069e-01 1.23026036e-01 1.41123325e-03 4.36442244e-04\n",
      " 2.99248147e-04 3.83386624e-05 2.42138355e-05 1.81484824e-05\n",
      " 1.17355187e-05 9.51761183e-06 6.53847012e-06 3.94303670e-06\n",
      " 3.66096156e-06 2.77102300e-06 1.71005295e-06 1.53378475e-06\n",
      " 1.36852079e-06 9.92044386e-07 7.83211227e-07 5.82470889e-07\n",
      " 5.34925480e-07 4.91560998e-07 4.46075073e-07 3.80841837e-07\n",
      " 3.48654846e-07 3.00689568e-07 2.49532067e-07 2.34531521e-07\n",
      " 2.14977692e-07 2.06817798e-07 1.97149898e-07 1.70072105e-07\n",
      " 1.61368239e-07 1.40118463e-07 1.35773204e-07 1.14055467e-07\n",
      " 1.05263440e-07 1.00616233e-07 8.31834004e-08 7.62803143e-08\n",
      " 5.27065307e-08 5.06248939e-08 3.95591977e-08 3.84858143e-08\n",
      " 2.85278237e-08 2.56475514e-08 2.41482015e-08 1.96018444e-08\n",
      " 1.81559146e-08 1.32782283e-08 1.27025098e-08 1.11327980e-08\n",
      " 1.07768402e-08 8.91555542e-09 8.58903977e-09 6.97161814e-09\n",
      " 6.36384315e-09 5.23495419e-09 4.99695901e-09 4.67522975e-09\n",
      " 3.88619254e-09 3.85158142e-09 3.23801646e-09 3.07849392e-09\n",
      " 2.85688820e-09 2.61038915e-09 2.47397809e-09 2.21677505e-09\n",
      " 2.08265509e-09 1.89656998e-09 1.71287313e-09 1.65775575e-09\n",
      " 1.47155053e-09 1.30644318e-09 1.29843051e-09 1.19442626e-09\n",
      " 1.15949155e-09 1.01074752e-09 9.37205561e-10 8.42791286e-10\n",
      " 8.13397833e-10 7.22045319e-10 6.58990149e-10 5.71748853e-10\n",
      " 5.43961878e-10 4.80314699e-10 4.51291505e-10 4.05204046e-10\n",
      " 3.81850954e-10 3.63924413e-10 3.28272037e-10 3.12470829e-10\n",
      " 3.02974489e-10 2.75049823e-10 2.58981687e-10 2.34777511e-10\n",
      " 2.28800889e-10 1.90527866e-10 1.82883771e-10 1.62230656e-10\n",
      " 1.52943502e-10 1.46510454e-10 1.11222640e-10 9.22106239e-11\n",
      " 8.57756979e-11 7.70013546e-11 6.67303241e-11 5.94293220e-11\n",
      " 5.70090785e-11 5.23427110e-11 5.01667358e-11 4.69628984e-11\n",
      " 4.27518283e-11 4.06280108e-11 3.46769984e-11 2.42379871e-11\n",
      " 2.17407284e-11 1.64725046e-11 1.11582706e-11 1.05670852e-11\n",
      " 9.79855014e-12 6.62562418e-12 6.10544705e-12 2.96092585e-12\n",
      " 1.86055525e-12 9.65734421e-13 5.60435488e-13 4.06189951e-14]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pc_T(y, nfac):\n",
    "    # y is a TxN matrix of data\n",
    "    # nfac is the number of factors to extract\n",
    "\n",
    "    bigt, bign = y.shape\n",
    "\n",
    "    yy = np.dot(y.T, y)\n",
    "\n",
    "    eigval, Fhat0 = np.linalg.eigh(yy)\n",
    "    eigval = eigval[::-1]    # Eigenvalues are in ascending order by default, so reversing them to match Matlab code\n",
    "    Fhat0 = Fhat0[:, ::-1]   # Eigenvectors are sorted by corresponding eigenvalues, so reversing the order\n",
    "\n",
    "    fhat = np.dot(Fhat0[:, :nfac], np.sqrt(bigt))\n",
    "    print(fhat.shape, \"fhat shape\")\n",
    "\n",
    "    lambda_ = np.matmul(y,fhat) / bigt\n",
    "    print(lambda_.shape, \"lambda shape\")\n",
    "\n",
    "    f_dot_lambda = np.dot(fhat, lambda_.T)\n",
    "    print(f_dot_lambda.shape, \"f_dot_lambda shape\")\n",
    "\n",
    "    ehat = y - f_dot_lambda.T\n",
    "\n",
    "    ve2 = np.sum(ehat ** 2, axis=1) / bign\n",
    "\n",
    "    ss = eigval\n",
    "\n",
    "    # Return the results\n",
    "    return ehat, fhat, lambda_, ve2, ss, eigen_vectors\n",
    "\n",
    "# Get the explained variances from pca\n",
    "ehat, fhat, lambda_, ve2, eigen_values, _ = pc_T(data,5)\n",
    "print(eigen_values/np.sum(eigen_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "def predict_pca(data, h_steps=1, response='CPIAUCSL', test_start='1985-01-01'):\n",
    "    # Split into train and test sets with train ending at december 1984\n",
    "    initial_train = data[:test_start]\n",
    "    initial_test = data[test_start:]\n",
    "\n",
    "    T_train = initial_train.shape[0]\n",
    "    T_test = initial_test.shape[0]\n",
    "    T = data.shape[0]\n",
    "\n",
    "    # Split into X and y\n",
    "    X = data\n",
    "    y = data[response]\n",
    "\n",
    "    # Shift y by h steps\n",
    "    y = y.shift(h_steps)\n",
    "\n",
    "    # Initialize the list of MSE's\n",
    "    preds = []\n",
    "    actuals = []\n",
    "\n",
    "\n",
    "    # t is where the test set start\n",
    "    for t in range(T_train, T):\n",
    "\n",
    "        # Split into X and y, dropping first h rows from training data to account for the shift\n",
    "        X_train, y_train = X[h_steps:t], y[h_steps:t]\n",
    "        X_test, y_test = X[t:(t + h_steps)], y[t:(t + h_steps)]\n",
    "        \n",
    "        # Scale the features by the slope of the regression line\n",
    "        X_train = scale_X(X_train, y_train)\n",
    "\n",
    "        # Apply PCA to the features\n",
    "        pca = PCA(n_components=5)\n",
    "        pca.fit(X_train)\n",
    "        \n",
    "        # Transform the training and test sets\n",
    "        X_train_pca = pca.transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test.values)\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_pca, y_train)    \n",
    "\n",
    "        # Make predictions 1 step ahead\n",
    "        y_pred = model.predict(X_test_pca)\n",
    "\n",
    "        # Compute the MSE\n",
    "        preds.append(y_pred)\n",
    "        actuals.append(y_test.values)\n",
    "\n",
    "\n",
    "    return actuals, preds\n",
    "\n",
    "def scale_X(X_train, y_train):\n",
    "    X_train = X_train.copy()\n",
    "    T = X_train.shape[0]\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_standardized = scaler.fit_transform(X_train)\n",
    "\n",
    "    slopes = []\n",
    "\n",
    "    for i in range(X_train.shape[1]):\n",
    "        # Seperate the predictor from the rest of the data\n",
    "        X_predictor = X_train_standardized[:,i].reshape(-1, 1)\n",
    "\n",
    "        # Fit the model\n",
    "        lr = LinearRegression(fit_intercept=True)\n",
    "        lr.fit(X_predictor, y_train)\n",
    "\n",
    "        # Obtain the slope coefficient which is the beta\n",
    "        slope = lr.coef_\n",
    "        slopes.append(slope)\n",
    "\n",
    "    scaler_demean = StandardScaler(with_mean=False, with_std=False)\n",
    "    X_train_demeaned = scaler_demean.fit_transform(X_train)\n",
    "\n",
    "    for i, slope in enumerate(slopes):\n",
    "        X_train_demeaned[:,i] = X_train_demeaned[:,i] * slope\n",
    "\n",
    "    return np.sqrt(T) * X_train_demeaned\n",
    "\n",
    "def compute_R2(actuals, preds):\n",
    "    SSR = []\n",
    "    SST = []\n",
    "    for i in range(len(actuals)):\n",
    "        SSR.append(np.sum((actuals[i] - preds[i])**2))\n",
    "        SST.append(np.sum((actuals[i] - np.mean(actuals[i]))**2))\n",
    "\n",
    "    SSR = np.sum(SSR)\n",
    "    SST = np.sum(SST)\n",
    "\n",
    "    print(\"SSR: \", SSR, \"SST: \", SST)\n",
    "    R2 = 1 - SSR/SST\n",
    "    return R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vincent\\AppData\\Local\\Temp\\ipykernel_8508\\2042118580.py:95: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = 1 - np.sum(SSR)/np.sum(SST)\n"
     ]
    }
   ],
   "source": [
    "actual_y, predicted_y = predict_pca(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSR:  1930.893431008673 SST:  0.0\n",
      "-inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vincent\\AppData\\Local\\Temp\\ipykernel_8508\\2607139705.py:99: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = 1 - SSR/SST\n"
     ]
    }
   ],
   "source": [
    "print(compute_R2(actual_y, predicted_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
