{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from src.helpers.functions import get_data, pc_T, predict_pca, estimate_AR_res, generate_data\n",
    "from src.helpers.functions import select_AR_lag_SIC, winsor, lag_matrix\n",
    "from src.helpers.refactored import ar_forecast, scale_X, reduce_dims, loocv_ts, standardize\n",
    "from src.helpers.autoencoder import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_sample(X, y, dim_method=\"ae\", nfac=5):\n",
    "    \"\"\" Function to perform out of sample forecasting \"\"\"\n",
    "    h = 1\n",
    "    T = y.shape[0]\n",
    "\n",
    "    M = (1984-1959)*12  # In sample periods\n",
    "    N = T - M  # Out of sample periods\n",
    "\n",
    "    forecast_pca = np.zeros((N, 1))  # Forecast errors of PCA \n",
    "    forecast_spca = np.zeros((N, 1))  # Forecast errors of scaled PCA\n",
    "    forecast_ar = np.zeros((N, 1))  # Forecast errors of AR model\n",
    "    actual_y = np.zeros((N, 1))  # Actual values of y\n",
    "\n",
    "    # Initialize the regression models\n",
    "    reg_pc = LinearRegression()\n",
    "    reg_spc = LinearRegression()\n",
    "\n",
    "    p_max = 1  # Max number of lags for AR(p) model\n",
    "    scale_method = \"distance_correlation\"\n",
    "    \n",
    "    if dim_method == \"ae\":\n",
    "        # Initialize the autoencoder\n",
    "        ae = Autoencoder(input_dim=X.shape[1], hidden_dim=nfac, activation=nn.SiLU, layer_dims=[120, 60])\n",
    "\n",
    "        # Train the autoencoder on the in sample data\n",
    "        ae.train(standardize(X[:M, :]))\n",
    "        print(\"Initial training done\")\n",
    "    else:\n",
    "        ae = None\n",
    "\n",
    "    # Loop over all out of sample periods\n",
    "    for n in range(N):\n",
    "        #print(\"Forecast {} out of {}\".format(n, N))\n",
    "\n",
    "        # Use all available data up to time t\n",
    "        X_t = X[:(M + n), :]\n",
    "        y_t = y[:M + n]\n",
    "        actual_y[n] = y[M + n]\n",
    "\n",
    "        # Standardize the data\n",
    "        X_t = (X_t - np.mean(X_t, axis=0)) / np.std(X_t, axis=0)\n",
    "\n",
    "        # Get number lags\n",
    "        p_AR_star_n = select_AR_lag_SIC(y_t, h, p_max=p_max)\n",
    "\n",
    "        # Compute the forecast of the AR model\n",
    "        forecast_ar[n] = ar_forecast(p_AR_star_n, y_t, h)\n",
    "        \n",
    "        #### STEP 1: Scaling factors ####\n",
    "\n",
    "        # Compute the betas for scaling the variables\n",
    "        beta = scale_X(X_t, y_t, h, method=scale_method, p_AR_star_n=p_AR_star_n)\n",
    "        \n",
    "        # Winsorizing the betas\n",
    "        beta_win = winsor(np.abs(beta), p=(0, 100))\n",
    "\n",
    "        # Scale the factors by the winsorized betas\n",
    "        scaleX_t = X_t * beta_win\n",
    "\n",
    "        #### Intermezzo: Find the optimal number of factors ####\n",
    "        \n",
    "        #if n == 0:\n",
    "        #    nfac = loocv_ts(X=X_t, y=y_t, h=h, p_AR_star_n=p_AR_star_n, method=\"pca\")\n",
    "        \n",
    "        #### STEP 2: Dimension Reduction ####            \n",
    "\n",
    "        # Compute the reduced dimensionality representation of the factors\n",
    "        #x_pc = reduce_dims(X=X_t, nfac=nfac, method=\"pca\")\n",
    "        x_spc = reduce_dims(X=scaleX_t, nfac=nfac, method=dim_method, dim_red_model=ae)\n",
    "\n",
    "        #### STEP 3: Forecasting ####\n",
    "\n",
    "        # Add lag of y_t to the factors\n",
    "        if p_AR_star_n > 0:\n",
    "            #x_pc = lag_matrix(x_pc, y_t, p_AR_star_n)\n",
    "            x_spc = lag_matrix(x_spc, y_t, p_AR_star_n)\n",
    "            y_t = y_t[p_AR_star_n-1:]\n",
    "            \n",
    "        # Estimate regression coefficients\n",
    "        #reg_pc.fit(x_pc[:-h], y_t[h:])\n",
    "        reg_spc.fit(x_spc[:-h], y_t[h:])\n",
    "        \n",
    "        # Compute the forecast of the PCA and scaled PCA model\n",
    "        #forecast_pca[n] = reg_pc.predict(x_pc[-1].reshape(1, -1))\n",
    "        forecast_spca[n] = reg_spc.predict(x_spc[-1].reshape(1, -1))\n",
    "\n",
    "    # Compute the forecast errors\n",
    "    error_pca = actual_y - forecast_pca\n",
    "    error_spca = actual_y - forecast_spca\n",
    "    error_ar = actual_y - forecast_ar\n",
    "    \n",
    "    # Compute the R squared out of sample against the AR model\n",
    "    SSE_pca = np.sum(error_pca**2)\n",
    "    SSE_spca = np.sum(error_spca**2)\n",
    "    SSE_ar = np.sum(error_ar**2)\n",
    "\n",
    "    R2_spca = (1 - SSE_spca / SSE_ar)\n",
    "    R2_pca = (1 - SSE_pca / SSE_ar)\n",
    "\n",
    "    print(\"R2_spca: \", round(R2_spca * 100, 2))\n",
    "    print(\"R2_pca: \", round(R2_pca* 100, 2))\n",
    "    \n",
    "    return {\"error_pca\": error_pca,\n",
    "            \"error_spca\": error_spca,\n",
    "            \"error_ar\": error_ar,\n",
    "            \"R2_spca\": R2_spca,\n",
    "            \"R2_pca\": R2_pca}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of X:  (720, 123) Shape of y:  (720,)\n"
     ]
    }
   ],
   "source": [
    "variables = get_data()\n",
    "X = variables['data'].values\n",
    "y = variables['unemployment'].values\n",
    "\n",
    "print(\"Shape of X: \", X.shape, \"Shape of y: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:  inflation\n"
     ]
    }
   ],
   "source": [
    "# Set seed of numpy and torch\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Run the forecasting exercise\n",
    "for target in variables.keys():\n",
    "    if target != 'inflation':\n",
    "        continue\n",
    "    print(\"Target: \", target)\n",
    "    y = variables[target].values\n",
    "    result = out_sample(X = X, y = y, dim_method=\"ae\", nfac=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression scaling, kpca RBF\n",
    "Target:  inflation \n",
    "R2_spca:  12.39\n",
    "R2_pca:  -0.76\n",
    "Target:  unemployment\n",
    "R2_spca:  17.22\n",
    "R2_pca:  10.12\n",
    "Target:  ip_growth\n",
    "R2_spca:  13.22\n",
    "R2_pca:  7.88\n",
    "Target:  volatility\n",
    "R2_spca:  5.4\n",
    "R2_pca:  1.13\n",
    "\n",
    "#### Distance correlation scaling, kpca RBF\n",
    "Target:  inflation\n",
    "R2_spca:  9.03\n",
    "R2_pca:  -0.76\n",
    "Target:  unemployment\n",
    "R2_spca:  17.59\n",
    "R2_pca:  10.12\n",
    "Target:  ip_growth\n",
    "R2_spca:  10.88\n",
    "R2_pca:  7.88\n",
    "Target:  volatility\n",
    "R2_spca:  5.66\n",
    "R2_pca:  1.13\n",
    "\n",
    "#### Distance correlation scaling, kpca poly(5)\n",
    "Target:  inflation\n",
    "R2_spca:  9.73\n",
    "R2_pca:  -0.76\n",
    "Target:  unemployment\n",
    "R2_spca:  18.86\n",
    "R2_pca:  10.12\n",
    "Target:  ip_growth\n",
    "R2_spca:  12.63\n",
    "R2_pca:  7.88\n",
    "Target:  volatility\n",
    "R2_spca:  4.63\n",
    "R2_pca:  1.13\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_ar = result['error_ar']\n",
    "errors_pca = result['error_pca']\n",
    "errors_spca = result['error_spca']\n",
    "\n",
    "#errors = pd.DataFrame({'errors_ar': errors_ar, 'errors_pca': errors_pca.flatten()})\n",
    "#np.set_printoptions(formatter={'all':lambda x: str(x)[:7]})\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "mse_ar = np.mean(errors_ar**2)\n",
    "mse_pca = np.mean(errors_pca**2)\n",
    "mse_spca = np.mean(errors_spca**2)\n",
    "\n",
    "print(\"MSE AR: \", mse_ar)\n",
    "print(\"MSE PCA: \", mse_pca)\n",
    "print(\"MSE SPCA: \", mse_spca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
